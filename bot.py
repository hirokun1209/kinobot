import os
import io
import re
import base64
import asyncio
import unicodedata
from typing import List, Tuple, Dict, Optional

import discord
from discord.ext import commands
from PIL import Image, ImageDraw, ImageOps

# Google Vision
from google.cloud import vision

# OpenAI (official SDK v1)
from openai import OpenAI

# ---------------------------
# ENV/bootstrap
# ---------------------------
DISCORD_TOKEN = os.environ.get("DISCORD_TOKEN", "")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
GOOGLE_CLOUD_VISION_JSON = os.environ.get("GOOGLE_CLOUD_VISION_JSON", "")

if not DISCORD_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("DISCORD_TOKEN / OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚")

# Google Vision èªè¨¼ï¼ˆJSONæ–‡å­—åˆ—â†’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
if GOOGLE_CLOUD_VISION_JSON:
    cred_path = "/tmp/gcv_credentials.json"
    with open(cred_path, "w", encoding="utf-8") as f:
        f.write(GOOGLE_CLOUD_VISION_JSON)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = cred_path

gcv_client = vision.ImageAnnotatorClient()
oai_client = OpenAI(api_key=OPENAI_API_KEY)

# ---------------------------
# Discord Bot
# ---------------------------
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

# ---------------------------
# Parameters / Config
# ---------------------------

# å…¥åŠ›ç”»åƒã¯æœ€åˆã«æ¨ªå¹…708ã¸ç­‰æ¯”ãƒªã‚µã‚¤ã‚º
TARGET_WIDTH = 708

# ã‚¹ãƒ©ã‚¤ã‚¹å¢ƒç•Œï¼ˆ%ï¼‰
CUTS = [7.51, 11.63, 25.21, 29.85, 33.62, 38.41, 61.90]  # ä¸Šã‹ã‚‰ã®å¢ƒç•Œï¼…
# æ®‹ã™ãƒ–ãƒ­ãƒƒã‚¯ç•ªå·ï¼ˆ1å§‹ã¾ã‚Šï¼‰
KEEP = [2, 4, 6, 7]

# æ¨ªæ–¹å‘ãƒˆãƒªãƒŸãƒ³ã‚°ï¼ˆå·¦/å³ã‚’ï¼…ã§ã‚«ãƒƒãƒˆï¼‰
TRIM_RULES = {
    7: (20.0, 50.0),   # é§é¨ãƒŠãƒ³ãƒãƒ¼ï¼‹å…æˆ¦æ™‚é–“
    6: (32.48, 51.50), # ã‚µãƒ¼ãƒãƒ¼ç•ªå·
    4: (44.0, 20.19),  # åœæˆ¦çµ‚äº†
    2: (75.98, 10.73), # æ™‚è¨ˆ
}

# æ­£è¦è¡¨ç¾ï¼ˆç·©ã‚ï¼‰
RE_IMMUNE = re.compile(r"å…\s*æˆ¦\s*ä¸­")                                 # ã€Œå…æˆ¦ä¸­ã€
RE_TITLE  = re.compile(r"è¶Š\s*åŸŸ\s*é§[\u4E00-\u9FFF]{1,3}\s*å ´")         # ã€Œè¶ŠåŸŸé§ã€‡å ´ã€èª¤OCRã‚‚æ‹¾ã†
RE_TIME   = re.compile(r"\d{1,2}[:ï¼š]\d{2}(?:[:ï¼š]\d{2})?")              # 05:53 / 01:02:13 ãªã©
RE_SERVER = re.compile(r"\[?\s*[sS]\s*([0-9]{2,5})\]?")                 # [s1296] / s1296

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ–ãƒ­ãƒƒã‚¯é«˜ã•ã«å¯¾ã™ã‚‹â€œå¿…ãšæ®‹ã™â€ä¸Šéƒ¨å‰²åˆ
FALLBACK_KEEP_TOP_RATIO = 0.35

# ---------------------------
# Helpers
# ---------------------------

def _norm(s: str) -> str:
    return unicodedata.normalize("NFKC", s).replace(" ", "")

def load_image_from_bytes(data: bytes) -> Image.Image:
    im = Image.open(io.BytesIO(data))
    im = ImageOps.exif_transpose(im)  # EXIFã®å‘ãã‚’è£œæ­£
    return im.convert("RGBA")

def resize_to_width(im: Image.Image, width: int = TARGET_WIDTH) -> Image.Image:
    if im.width == width:
        return im
    h = int(round(im.height * width / im.width))
    return im.resize((width, h), Image.LANCZOS)

def slice_exact_7(im: Image.Image, cuts_pct: List[float]) -> List[Image.Image]:
    """å¢ƒç•Œï¼…ã‹ã‚‰7ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ï¼ˆ1..7ï¼‰"""
    w, h = im.size
    boundaries = [int(round(h * p / 100.0)) for p in cuts_pct]
    y = [0] + boundaries + [h]
    parts = []
    for i in range(7):
        parts.append(im.crop((0, y[i], w, y[i+1])))
    return parts

def trim_lr_percent(im: Image.Image, left_pct: float, right_pct: float) -> Image.Image:
    w, h = im.size
    left = int(round(w * left_pct / 100.0))
    right = w - int(round(w * right_pct / 100.0))
    left = max(0, min(left, w - 1))
    right = max(left + 1, min(right, w))
    return im.crop((left, 0, right, h))

def google_ocr_word_boxes(pil_im: Image.Image) -> List[Tuple[str, Tuple[int,int,int,int]]]:
    """Google Vision ã§ word å˜ä½ã®æ–‡å­—ã¨ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¿”ã™ (text, (x1,y1,x2,y2))"""
    buf = io.BytesIO()
    pil_im.convert("RGB").save(buf, format="JPEG", quality=95)
    image = vision.Image(content=buf.getvalue())

    response = gcv_client.document_text_detection(image=image)
    if response.error.message:
        raise RuntimeError(response.error.message)

    words: List[Tuple[str, Tuple[int,int,int,int]]] = []
    if not response.full_text_annotation.pages:
        return words

    for page in response.full_text_annotation.pages:
        for block in page.blocks:
            for para in block.paragraphs:
                for word in para.words:
                    txt = "".join([s.text for s in word.symbols])
                    xs = [v.x for v in word.bounding_box.vertices]
                    ys = [v.y for v in word.bounding_box.vertices]
                    x1, x2 = min(xs), max(xs)
                    y1, y2 = min(ys), max(ys)
                    words.append((txt, (x1, y1, x2, y2)))
    return words

def google_ocr_line_boxes(pil_im: Image.Image, y_tol: int = 18) -> List[Tuple[str, Tuple[int,int,int,int]]]:
    """
    wordã‚’Yåº§æ¨™ã§è¡Œã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ (line_text, (x1,y1,x2,y2)) ã‚’è¿”ã™ã€‚
    y_tol ã¯åŒä¸€è¡Œã¨ã¿ãªã™ä¸Šä¸‹è¨±å®¹ãƒ”ã‚¯ã‚»ãƒ«ã€‚
    """
    words = google_ocr_word_boxes(pil_im)
    if not words:
        return []

    # ä¸­å¿ƒYã§ã‚½ãƒ¼ãƒˆ
    items = []
    for txt, (x1, y1, x2, y2) in words:
        cy = (y1 + y2) / 2.0
        items.append((cy, x1, y1, x2, y2, txt))
    items.sort(key=lambda t: (t[0], t[1]))

    lines: List[List[Tuple[int,int,int,int,str]]] = []
    for cy, x1, y1, x2, y2, txt in items:
        if not lines:
            lines.append([(x1, y1, x2, y2, txt)])
            continue
        last = lines[-1]
        ly1 = min(a[1] for a in last)
        ly2 = max(a[3] for a in last)
        lcy = (ly1 + ly2) / 2.0
        if abs(cy - lcy) <= y_tol:
            last.append((x1, y1, x2, y2, txt))
        else:
            lines.append([(x1, y1, x2, y2, txt)])

    line_boxes: List[Tuple[str, Tuple[int,int,int,int]]] = []
    for chunks in lines:
        chunks.sort(key=lambda a: a[0])  # x1
        text = "".join(c[4] for c in chunks)  # ã‚¹ãƒšãƒ¼ã‚¹ç„¡ã—ã§é€£çµï¼ˆæ—¥æœ¬èªã¯ã“ã‚Œã§OKï¼‰
        x1 = min(c[0] for c in chunks)
        y1 = min(c[1] for c in chunks)
        x2 = max(c[2] for c in chunks)
        y2 = max(c[3] for c in chunks)
        line_boxes.append((text, (x1, y1, x2, y2)))
    return line_boxes

def compact_7_by_removing_sections(pil_im: Image.Image) -> Image.Image:
    """
    7ç•ªãƒ–ãƒ­ãƒƒã‚¯å†…ã§ã€
      ãƒ»å„ã€Œè¶ŠåŸŸé§ã€‡å ´ã€è¡Œã‚’ã‚¿ã‚¤ãƒˆãƒ«ã¨ã¿ãªã™
      ãƒ»ã‚¿ã‚¤ãƒˆãƒ«iã®ä¸‹ç«¯ã€œã‚¿ã‚¤ãƒˆãƒ«i+1ã®ä¸Šç«¯ã‚’â€œãƒ¯ãƒ³ãƒ–ãƒ­ãƒƒã‚¯â€
      ãƒ»ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã€Œå…æˆ¦ä¸­ã€ã¾ãŸã¯æ™‚é–“ã£ã½ã„è¡Œ(05:53/01:02:13ç­‰)ãŒã‚ã‚Œã°ã€
         ãã®è¡Œã®ä¸‹ç«¯ã¾ã§ã‚’â€œæ®‹ã™â€ï¼ãã‚Œä»¥é™ã€œæ¬¡ã‚¿ã‚¤ãƒˆãƒ«ç›´ä¸Šã‚’å‰Šé™¤ï¼ˆè©°ã‚ã‚‹ï¼‰
      ãƒ»è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ãƒ–ãƒ­ãƒƒã‚¯ä¸Šéƒ¨ã®ä¸€å®šå‰²åˆ(FALLBACK_KEEP_TOP_RATIO)ã¯å¿…ãšæ®‹ã™
      ãƒ»æœ€å¾Œã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ç”»åƒä¸‹ç«¯ã¾ã§ã‚’å¯¾è±¡
    """
    im = pil_im.copy()
    w, h = im.size

    lines = google_ocr_line_boxes(im, y_tol=18)

    # ã‚¿ã‚¤ãƒˆãƒ«è¡Œãƒ»å…æˆ¦/æ™‚é–“è¡Œã®Yç¯„å›²æŠ½å‡º
    titles: List[Tuple[int,int]] = []   # (top, bottom)
    candidates: List[Tuple[int,int]] = []  # (top, bottom) for å…æˆ¦ä¸­ or æ™‚é–“

    for text, (x1, y1, x2, y2) in lines:
        t = _norm(text)
        if RE_TITLE.search(t):
            titles.append((y1, y2))
        if RE_IMMUNE.search(t) or RE_TIME.search(t):
            candidates.append((y1, y2))

    titles.sort(key=lambda p: p[0])
    candidates.sort(key=lambda p: p[0])

    if not titles:
        # ä½•ã‚‚æ¤œå‡ºã§ããªã‘ã‚Œã°åŸå›³ã‚’è¿”ã™ï¼ˆå®‰å…¨å´ï¼‰
        return im

    # â€œæ®‹ã™â€ç¸¦ã‚¹ãƒ©ã‚¤ã‚¹ã‚’é›†ã‚ã‚‹
    keep_slices: List[Tuple[int,int]] = []
    for i, (t_y1, t_y2) in enumerate(titles):
        start = t_y1
        end = titles[i + 1][0] if i + 1 < len(titles) else h

        if end <= start:
            continue

        # ã“ã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã§æœ€å¾Œã«å‡ºã‚‹å€™è£œã®bottomã‚’æ¡ç”¨
        cand_bottom = None
        for cy1, cy2 in candidates:
            if start <= cy1 < end:
                cand_bottom = cy2

        if cand_bottom is not None:
            cut_at = cand_bottom  # æ™‚é–“è¡Œã®ä¸‹ç«¯ã¾ã§ æ®‹ã™
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ–ãƒ­ãƒƒã‚¯ä¸Šéƒ¨ä¸€å®šå‰²åˆã¯æ®‹ã™ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã¯å¿…ãšå«ã‚ã‚‹ï¼‰
            cut_at = min(end, int(round(start + (end - start) * FALLBACK_KEEP_TOP_RATIO)))
            cut_at = max(cut_at, t_y2)

        if cut_at > start:
            keep_slices.append((start, cut_at))

    # ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ç¸¦ã«è©°ã‚ç›´ã™
    if not keep_slices:
        return im

    segments = [im.crop((0, a, w, b)) for (a, b) in keep_slices]
    out_h = sum(seg.height for seg in segments)
    out = Image.new("RGBA", (w, out_h), (0, 0, 0, 0))
    y = 0
    for seg in segments:
        out.paste(seg, (0, y))
        y += seg.height
    return out

def hstack(im_left: Image.Image, im_right: Image.Image, gap: int = 8, bg=(0,0,0,0)) -> Image.Image:
    """å·¦å³ã«çµåˆï¼ˆé«˜ã•ã¯å¤§ãã„æ–¹ã«åˆã‚ã›ä¸­å¤®å¯„ã›ï¼‰"""
    h = max(im_left.height, im_right.height)
    w = im_left.width + gap + im_right.width
    canvas = Image.new("RGBA", (w, h), bg)
    y1 = (h - im_left.height)//2
    y2 = (h - im_right.height)//2
    canvas.paste(im_left, (0, y1))
    canvas.paste(im_right, (im_left.width + gap, y2))
    return canvas

def vstack(images: List[Image.Image], gap: int = 8, bg=(0,0,0,0)) -> Image.Image:
    """ç¸¦çµåˆï¼ˆå¹…ã¯æœ€å¤§ã«åˆã‚ã›ä¸­å¤®å¯„ã›ï¼‰"""
    if not images:
        raise ValueError("no images to stack")
    max_w = max(img.width for img in images)
    total_h = sum(img.height for img in images) + gap*(len(images)-1)
    canvas = Image.new("RGBA", (max_w, total_h), bg)
    y = 0
    for img in images:
        x = (max_w - img.width)//2
        canvas.paste(img, (x, y))
        y += img.height + gap
    return canvas

# ---------------------------
# OpenAI OCR
# ---------------------------

def openai_ocr_png(pil_im: Image.Image) -> Tuple[str, bytes]:
    """OpenAI ã¸ç”»åƒOCRä¾é ¼ã€‚è¿”ã‚Šå€¤: (ãƒ†ã‚­ã‚¹ãƒˆ, é€ã£ãŸPNGãƒã‚¤ãƒˆåˆ—)"""
    buf = io.BytesIO()
    pil_im.convert("RGB").save(buf, format="PNG")
    png_bytes = buf.getvalue()

    b64 = base64.b64encode(png_bytes).decode("utf-8")
    resp = oai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": "ä»¥ä¸‹ã®ç”»åƒã«å†™ã£ã¦ã„ã‚‹æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ãã®ã¾ã¾èª­ã¿å–ã£ã¦ãã ã•ã„ï¼ˆæ”¹è¡Œã¨æ•°å­—ã‚‚ä¿æŒï¼‰ã€‚"},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}}
            ]
        }],
        temperature=0.0,
    )
    text = resp.choices[0].message.content.strip()
    return text, png_bytes

# ---------------------------
# è¨ˆç®— & ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
# ---------------------------

def _time_to_seconds(t: str) -> int:
    t = _norm(t).replace("ï¼š", ":")
    m = re.match(r"^(\d{1,2}):(\d{2})(?::(\d{2}))?$", t)
    if not m:
        return 0
    h = int(m.group(1))
    m_ = int(m.group(2))
    s = int(m.group(3)) if m.group(3) else 0
    return h*3600 + m_*60 + s

def _seconds_to_hms(sec: int) -> str:
    sec %= 24*3600
    h = sec // 3600
    m = (sec % 3600) // 60
    s = sec % 60
    return f"{h:02d}:{m:02d}:{s:02d}"

def parse_and_compute(oai_text: str) -> Tuple[Optional[str], Optional[str], Optional[str], List[Tuple[int, str]]]:
    """
    OCRãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰
      server(str), base_time(HH:MM:SS), ceasefire(HH:MM:SS), results[(place, time_str)]
    ã‚’è¿”ã™ã€‚è¶³ã‚Šãªã„å ´åˆã¯ Noneã€‚
    """
    lines = [ln.strip() for ln in oai_text.splitlines() if ln.strip()]
    if not lines:
        return None, None, None, []

    server = None
    base_time_sec: Optional[int] = None
    ceasefire_sec: Optional[int] = None

    pairs: List[Tuple[int, Optional[int]]] = []  # (place, immune_sec)

    def find_time_in_text(txt: str) -> Optional[str]:
        m = RE_TIME.search(txt)
        return m.group(0).replace("ï¼š", ":") if m else None

    # 1å‘¨: ã‚µãƒ¼ãƒãƒ¼ / åŸºæº– / åœæˆ¦çµ‚äº† / è¶ŠåŸŸé§ã€‡å ´ + å…æˆ¦ ã‚’é †ã«æ‹¾ã†
    for raw in lines:
        n = _norm(raw)
        # server
        if server is None:
            m = RE_SERVER.search(n)
            if m:
                server = m.group(1)

        # ceasefire: è¡Œå†…ã«ã€Œåœæˆ¦ã€ãŒã‚ã‚Œã°ãã®è¡Œã®æ™‚åˆ»ã‚’æ¡ç”¨ï¼ˆå‰å¾Œã©ã¡ã‚‰ã§ã‚‚OKï¼‰
        if "åœæˆ¦" in n:
            tt = find_time_in_text(raw)
            if tt:
                ceasefire_sec = _time_to_seconds(tt)
                # åœæˆ¦è¡Œã¯åŸºæº–ã§ã¯ãªã„ã®ã§ continue ã›ãšæ¬¡ã‚‚è¦‹ã‚‹ï¼ˆå•é¡Œãªã—ï¼‰

        # base_time: ã€Œå…æˆ¦ã€ã€Œåœæˆ¦ã€ã‚’å«ã¾ãªã„æœ€åˆã®æ™‚åˆ»
        if base_time_sec is None and ("å…æˆ¦" not in n and "åœæˆ¦" not in n):
            tt = find_time_in_text(raw)
            if tt:
                base_time_sec = _time_to_seconds(tt)

        # title: è¶ŠåŸŸé§ã€‡å ´
        if RE_TITLE.search(n):
            # ç•ªå·ã®æŠ½å‡ºï¼ˆæœ«å°¾æ•°å­— or ã€Œå ´ã€ã®å¾Œã®æ•°å­—ï¼‰
            m_num = re.search(r"å ´\s*([0-9]{1,3})", raw)
            if not m_num:
                m_num = re.search(r"([0-9]{1,3})\s*$", raw)
            if m_num:
                place = int(m_num.group(1))
                pairs.append((place, None))

        # immune time
        if "å…æˆ¦" in n:
            tt = find_time_in_text(raw)
            if tt:
                tsec = _time_to_seconds(tt)
                # ç›´è¿‘ã®æœªè¨­å®šãƒšã‚¢ã«å……å½“
                for i in range(len(pairs)-1, -1, -1):
                    if pairs[i][1] is None:
                        pairs[i] = (pairs[i][0], tsec)
                        break

    if base_time_sec is None or not pairs:
        return server, None, None, []

    # è¨ˆç®—
    calc: List[Tuple[int, int]] = []  # (place, sec_from_midnight)
    for place, immune in pairs:
        if immune is None:
            continue
        calc.append((place, (base_time_sec + immune) % (24*3600)))

    if not calc:
        return server, _seconds_to_hms(base_time_sec), _seconds_to_hms(ceasefire_sec) if ceasefire_sec is not None else None, []

    # æœ€ä¸Šãƒ–ãƒ­ãƒƒã‚¯ï¼ˆæœ€åˆã®calcï¼‰ã¨åœæˆ¦çµ‚äº†ã®å·®ã§è£œæ­£
    if ceasefire_sec is not None:
        delta = (ceasefire_sec - calc[0][1])  # æ­£è² OK
        calc = [(pl, (sec + delta) % (24*3600)) for (pl, sec) in calc]
        # å¿µã®ãŸã‚å…ˆé ­ã¯åœæˆ¦çµ‚äº†ã«åˆã‚ã›ã‚‹
        calc[0] = (calc[0][0], ceasefire_sec % (24*3600))

    # å‡ºåŠ›æ•´å½¢
    results: List[Tuple[int, str]] = [(pl, _seconds_to_hms(sec)) for (pl, sec) in calc]
    base_str = _seconds_to_hms(base_time_sec)
    cease_str = _seconds_to_hms(ceasefire_sec) if ceasefire_sec is not None else None
    return server, base_str, cease_str, results

def build_result_message(server: Optional[str],
                         base_str: Optional[str],
                         cease_str: Optional[str],
                         results: List[Tuple[int, str]]) -> str:
    # ä¾‹ï¼‰ âœ… è§£æå®Œäº†ï¼â±ï¸ åŸºæº–æ™‚é–“:17:26:45 (21:07:21)
    #      1296-2-21:07:21
    #      ...
    if not base_str or not results or not server:
        return "âš ï¸ è§£æå®Œäº†â€¦ ã§ã™ãŒè¨ˆç®—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ç”»åƒã‚„OCRçµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚"

    head = f"âœ… è§£æå®Œäº†ï¼â±ï¸ åŸºæº–æ™‚é–“:{base_str}"
    if cease_str:
        head += f" ({cease_str})"

    body_lines = [f"{server}-{pl}-{t}" for (pl, t) in results]
    return head + "\n" + "\n".join(body_lines)

# ---------------------------
# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
# ---------------------------

def process_image_pipeline(pil_im: Image.Image) -> Tuple[Image.Image, str, bytes, str]:
    """
    ãƒªã‚µã‚¤ã‚ºâ†’ã‚¹ãƒ©ã‚¤ã‚¹â†’ãƒˆãƒªãƒ â†’ï¼ˆ7ã‚’è©°ã‚å‡¦ç†ï¼‰â†’åˆæˆâ†’OpenAI OCRâ†’è¨ˆç®—
    æˆ»ã‚Šå€¤: (æœ€çµ‚åˆæˆç”»åƒ, OpenAI OCRãƒ†ã‚­ã‚¹ãƒˆ, OpenAIã¸é€ã£ãŸç”»åƒbytes, çµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
    """
    # ã¾ãšæ¨ªå¹…708ã¸
    base = resize_to_width(pil_im, TARGET_WIDTH)

    parts = slice_exact_7(base, CUTS)

    # 1..7 ã®ã†ã¡ 2/4/6/7 ã‚’æ®‹ã™
    kept: Dict[int, Image.Image] = {}
    for idx in KEEP:
        block = parts[idx - 1]
        l_pct, r_pct = TRIM_RULES[idx]
        kept[idx] = trim_lr_percent(block, l_pct, r_pct)

    # 7ç•ªï¼šä¸è¦éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¦è©°ã‚ã‚‹
    kept[7] = compact_7_by_removing_sections(kept[7])

    # 6ã®å³éš£ã« 2 ã‚’æ¨ªä¸¦ã³ï¼ˆæ™‚è¨ˆã¯ã‚µãƒ¼ãƒãƒ¼ç•ªå·ã®éš£ï¼‰
    top_row = hstack(kept[6], kept[2], gap=8)

    # ç¸¦ã« 4ã€7 ã‚’ä¸‹ã¸
    final_img = vstack([top_row, kept[4], kept[7]], gap=10)

    # OpenAI OCR
    oai_text, sent_png = openai_ocr_png(final_img)

    # è§£æï¼†æ•´å½¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    server, base_str, cease_str, results = parse_and_compute(oai_text)
    message = build_result_message(server, base_str, cease_str, results)

    return final_img, oai_text, sent_png, message

# ---------------------------
# Discord command
# ---------------------------

@bot.command(name="oaiocr", help="ç”»åƒã‚’æ·»ä»˜ã—ã¦å®Ÿè¡Œã€‚å‡¦ç†â†’è©°ã‚â†’OpenAI OCRâ†’è¨ˆç®—ã¾ã§è¡Œã„ã¾ã™ã€‚")
async def oaiocr(ctx: commands.Context):
    try:
        if not ctx.message.attachments:
            await ctx.reply("ç”»åƒã‚’æ·»ä»˜ã—ã¦ `!oaiocr` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return

        att: Optional[discord.Attachment] = None
        for a in ctx.message.attachments:
            if a.content_type and a.content_type.startswith("image/"):
                att = a
                break
        if att is None:
            await ctx.reply("ç”»åƒã®æ·»ä»˜ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        # ã¾ãšã¯å³ãƒ¬ã‚¹
        await ctx.reply("è§£æä¸­â€¦ğŸ”")

        data = await att.read()
        pil = load_image_from_bytes(data)

        loop = asyncio.get_event_loop()
        final_img, oai_text, sent_png, message = await loop.run_in_executor(None, process_image_pipeline, pil)

        out_buf = io.BytesIO()
        final_img.convert("RGB").save(out_buf, format="PNG")
        out_buf.seek(0)

        sent_buf = io.BytesIO(sent_png)
        sent_buf.seek(0)

        files = [
            discord.File(out_buf, filename="result.png"),
            discord.File(sent_buf, filename="sent_to_openai.png"),
        ]
        await ctx.reply(content=message, files=files)

    except Exception as e:
        await ctx.reply(f"ã‚¨ãƒ©ãƒ¼: {e}")

@bot.command(name="ping")
async def ping(ctx: commands.Context):
    await ctx.reply("pong ğŸ“")

if __name__ == "__main__":
    bot.run(DISCORD_TOKEN)